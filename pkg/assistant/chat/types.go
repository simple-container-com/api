package chat

import (
	"context"
	"time"

	"github.com/simple-container-com/api/pkg/assistant/analysis"
	"github.com/simple-container-com/api/pkg/assistant/llm"
)

// Message alias for llm.Message to avoid circular imports
type Message = llm.Message

// ConversationContext maintains the state of an ongoing conversation
type ConversationContext struct {
	ProjectPath  string                    `json:"project_path"`  // Path to the project being discussed
	ProjectInfo  *analysis.ProjectAnalysis `json:"project_info"`  // Analysis of the current project
	Mode         string                    `json:"mode"`          // "dev", "devops", or "general"
	History      []Message                 `json:"history"`       // Conversation history
	CurrentTopic string                    `json:"current_topic"` // Current conversation topic
	Resources    []string                  `json:"resources"`     // Available resources from parent
	Environment  string                    `json:"environment"`   // Current target environment
	UserIntent   string                    `json:"user_intent"`   // Inferred user intent
	SessionID    string                    `json:"session_id"`    // Unique session identifier
	CreatedAt    time.Time                 `json:"created_at"`    // Session creation time
	UpdatedAt    time.Time                 `json:"updated_at"`    // Last update time
}

// ChatCommand represents a command that can be executed during chat
type ChatCommand struct {
	Name        string         `json:"name"`        // Command name (e.g., "search", "analyze")
	Description string         `json:"description"` // Command description
	Usage       string         `json:"usage"`       // Usage example
	Handler     CommandHandler `json:"-"`           // Command handler function
	Aliases     []string       `json:"aliases"`     // Command aliases
	Args        []CommandArg   `json:"args"`        // Command arguments
}

// CommandArg represents an argument for a chat command
type CommandArg struct {
	Name        string `json:"name"`        // Argument name
	Type        string `json:"type"`        // Argument type (string, int, bool)
	Required    bool   `json:"required"`    // Whether argument is required
	Description string `json:"description"` // Argument description
	Default     string `json:"default"`     // Default value
}

// CommandHandler is a function that handles a chat command
type CommandHandler func(ctx context.Context, args []string, context *ConversationContext) (*CommandResult, error)

// CommandResult represents the result of a command execution
type CommandResult struct {
	Success  bool                   `json:"success"`   // Whether command succeeded
	Message  string                 `json:"message"`   // Result message
	Data     map[string]interface{} `json:"data"`      // Additional result data
	Files    []GeneratedFile        `json:"files"`     // Files generated by command
	NextStep string                 `json:"next_step"` // Suggested next step
}

// GeneratedFile represents a file generated during chat
type GeneratedFile struct {
	Path        string `json:"path"`        // File path
	Content     string `json:"content"`     // File content
	Type        string `json:"type"`        // File type (yaml, dockerfile, etc.)
	Description string `json:"description"` // File description
	Generated   bool   `json:"generated"`   // Whether file was generated vs updated
}

// ChatMetrics tracks metrics for chat sessions
type ChatMetrics struct {
	SessionDuration time.Duration `json:"session_duration"` // Total session duration
	MessageCount    int           `json:"message_count"`    // Total messages exchanged
	CommandsUsed    []string      `json:"commands_used"`    // Commands used in session
	FilesGenerated  int           `json:"files_generated"`  // Number of files generated
	TokensUsed      int           `json:"tokens_used"`      // Total LLM tokens used
	Errors          int           `json:"errors"`           // Number of errors encountered
}

// SessionConfig configures a chat session
type SessionConfig struct {
	Mode           string            `json:"mode"`            // Chat mode (dev, devops, general)
	ProjectPath    string            `json:"project_path"`    // Project path
	LLMProvider    string            `json:"llm_provider"`    // LLM provider (openai, local, etc.)
	APIKey         string            `json:"api_key"`         // LLM provider API key
	MaxTokens      int               `json:"max_tokens"`      // Maximum tokens per response
	Temperature    float32           `json:"temperature"`     // LLM temperature setting
	EnableCommands bool              `json:"enable_commands"` // Enable chat commands
	LogLevel       string            `json:"log_level"`       // Logging level
	Metadata       map[string]string `json:"metadata"`        // Additional session metadata
}

// DefaultSessionConfig returns default session configuration
func DefaultSessionConfig() SessionConfig {
	return SessionConfig{
		Mode:           "general",
		LLMProvider:    "openai",
		MaxTokens:      2048,
		Temperature:    0.7,
		EnableCommands: true,
		LogLevel:       "info",
		Metadata:       make(map[string]string),
	}
}
